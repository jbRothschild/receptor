\subsection{\label{sec:mode1}Mode 1}

We start with the process that creates a product $n$ with rate $k_p$ when a ligand is bound to the receptor. It binds with rate $k_{on}c$ and unbinds with rate $k_off$ to the receptor.

(Need to make the figure for this)

The master equations are

\begin{equation}
\begin{aligned}
 \dot{P_0^n} &= k_{off}P_1^n -k_{on}cP_0^n \\
 \dot{P_1^n} &= k_{on}cP_0^n -k_{off}P_1^n + k_pP_1^{n-1} - k_pP_1^{n}.
\end{aligned}
\end{equation}

What we are interested in this equation is the average and variance of the prouct $n$ within the cell as we can find what the best estimate the cell can make of the ligand concentration outside. Anton also argues that a second quantity is important, the cell needs to also estimate $k_{off}$ to know what is the identity of this ligand. There are a couple ways to solve this system: generating functions is one venue but is difficult to solve analytically. Using this method, Anton gets a certain average and standard deviation

Instead, we will try another method using the master equation. Note that we will use the solution for the probability of being bound as a function of time (derived by Anton and confirmed by us, type it out)

\begin{equation}
\begin{aligned}
P_1(t) & =  P_1^{ss}(1-e^{-rt}) + P_1(0)e^{-rt}\\
	   & = \frac{x}{1+x} + \Delta_1 e^{-rt}
\end{aligned}
\end{equation}

where

\begin{equation*}
\begin{aligned}
P^{ss} & = \frac{x}{1+x}\\
r & = k_{on}c + k_{off}\\
\Delta_1 & = P_1(0) - P_1^{ss}.
\end{aligned}
\end{equation*}

We write down the time derivative of average $n$ and replace terms by the master equations to solve the equation

\begin{equation*}
\begin{aligned}
\dot{ \langle n \rangle } & = \sum_{n=0} n (\dot{P_0^n} + \dot{P_1^n})\\
                          & = k_p \sum_{n=0} n (P_1^{n-1} - P_1^n)\\
                          & = k_p \sum_{n=0} P_1^{n}\\
                          & = k_p P_1(t).
\end{aligned}
\end{equation*}

Replacing our expression in equation 2 in this formula, we integrate to get the solution

\begin{equation}
\langle n \rangle = k_p \frac{x}{1+x}t + n_0 + \frac{k_p \Delta_1}{r}(1-e^{-rt}).
\end{equation}

Assuming that the initial product number $n_0=0$ and that the initial probability of being bound is the same as steady state $\Delta = P_1(0) - P_1^{ss} = 0$ we find

\begin{equation*}
\langle n \rangle = k_p \frac{x}{1+x}t.
\end{equation*}

For the variance, as similar approach can be taken

\begin{equation*}
\begin{aligned}
\dot{ \langle n^2 \rangle } & = \sum_{n=0} n^2 (\dot{P_0^n} + \dot{P_1^n})\\
                          & = k_p \sum_{n=0} n^2 (P_1^{n-1} - P_1^n)\\
                          & = k_p \sum_{n=0} (n+1)^2 P_1^{n} - n^2 P_1^n\\
                          & = k_p \sum_{n=0} (2n+1)P_1^{n}\\
                          & = k_p (2 \sum_{n=0}nP_1^{n} + \sum_{n=0}P_1^{n})\\
                          & = k_p (2 \langle n \rangle + P_1(t))
\end{aligned}
\end{equation*}

By using the expression for $\langle n \rangle$ in equation 3 we can integrate to obtain $\langle n^2 \rangle$

\begin{equation}
\begin{aligned}
\langle n^2 \rangle & = {k_p}^2 \frac{x}{1+x}t^2 + 2k_pn_0t + 2\frac{{k_p}^2 \Delta_1}{r^2}(rt -1 + e^{-rt}) + \langle n \rangle.
\end{aligned}
\end{equation}

It is straightforward at this point to combine equations 3 and 4 to obtain the variance

\begin{equation}
\begin{aligned}
Var(n) & = \langle n^2 \rangle - {\langle n \rangle}^2\\
	   & = k_p \frac{x}{1+x}t^2 + 2k_pn_0t + \frac{2k_p \Delta_1}{r^2}(rt-1+e^{-rt}) + \langle n \rangle \\
	   & \qquad - {\langle n \rangle}^2
\end{aligned}
\end{equation}

If $\Delta_1 = P_1(0) - P_1^{ss} = 0$ and $n_0$=0

\begin{equation}
\begin{aligned}
Var(n) &  = {k_p}^2 \frac{x}{1+x}t^2 + {k_p} \frac{x}{1+x}t - {k_p}^2 \frac{x^2}{(1+x)^2}t^2 \\
		& = {k_p}^2\frac{x}{(1+x)^2}t^2 + k_p\frac{x}{1+x}t \\
		& = k_p \frac{x}{1+x}t(k_p\frac{1}{1+x}t + 1)
\end{aligned}
\end{equation}



